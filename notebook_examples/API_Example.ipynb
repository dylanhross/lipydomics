{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Lipidomics Data Analysis (API)\n",
    "_(lipydomics version: 1.4.x)_\n",
    "\n",
    "---\n",
    "## 1) Initialize a Dataset\n",
    "We will be using `example_raw.csv` as the raw data file for this work (the data is positive mode and has not been normalized). We first need to initialize a lipydomics dataset from the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=False,\n",
       "\tnormalized=False,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices=None,\n",
       "\tstats={}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.data import Dataset\n",
    "\n",
    "dset = Dataset('example_raw.csv', esi_mode='pos')\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now done the bare minimum to load the data and we have a lipydomics dataset initialized. We can see from the overview that there are 16 samples and 3342 features in this dataset. \n",
    "  \n",
    "---\n",
    "## 2) Prepare the Dataset\n",
    "### 2.1) Assign Groups\n",
    "Currently, we have 16 samples in our dataset, but we have not provided any information on what groups they belong to. We will assign them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=False,\n",
       "\tnormalized=False,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary mapping group identifiers (str) to sample indices (int)\n",
    "group_idx = {\n",
    "    '0641': [0, 1, 2, 3],\n",
    "    'geh': [4, 5, 6, 7],\n",
    "    'sal': [8, 9, 10, 11],\n",
    "    'wt': [12, 13, 14, 15]\n",
    "}\n",
    "dset.assign_groups(group_idx)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of the samples have been assigned to one of four groups: `0641`, `geh`, `sal1`, and `wt`. These group IDs will be used later on when we select data or perform statistical analyses. \n",
    "  \n",
    "### 2.2) Normalize Intensities\n",
    "Currently, the feature intensities are only raw values. We are going to normalize them using weights derived from an external normalization factor (pellet masses), but we also have the option to normalize to the signal from an internal standard if desired. The normalization weights are in `weights.txt`, a simple text file with the weights for each sample, one per line (16 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=False,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={}\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "weights = genfromtxt('weights.txt')\n",
    "dset.normalize(weights)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the dataset overview we can see that we now have assigned all of our samples to groups and we have a table of normalized intensities.\n",
    "  \n",
    "  \n",
    "### 2.3) Identify Lipids\n",
    "Another dataset preparation step we can perform before diving in to the data analysis is identifying as many lipids as possible. There are multiple identification criteria that take into account theoretical and measured m/z, retention time, and/or CCS, all of which vary in the level of confidence in the identifications they yield. We will use an approach that tries the highest confidence identification criteria first, then tries others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.identification import add_feature_ids\n",
    "\n",
    "tol = [0.025, 0.5, 3.0]  # tol must be a list\n",
    "# identify features at the highest level possible\n",
    "add_feature_ids(dset, tol, level='any')\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `any` identification level and m/z, retention time, and CCS tolerances of 0.025 0.5 3.0, respectively, 2063 lipids were identified. Now the dataset is fully prepared and we can start performing statistical analyses and generating plots. \n",
    "  \n",
    "  \n",
    "---\n",
    "## 3) Statistical Analyses and Plotting\n",
    "### 3.1) Compute ANOVA P-value for All Groups\n",
    "A common analysis performed on lipidomics data is calculating the p-value of each feature from an ANOVA using the intensities from all groups. This gives an indication of how the variance between groups compares to the variance within groups, and a significant p-value indicates that there is some significant difference in the intensities for a given feature between the different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/stats/stats.py:3349: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={\n",
       "\t\t\"ANOVA_0641-geh-sal-wt_normed\"\n",
       "\t}\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.stats import add_anova_p\n",
    "\n",
    "# compute ANOVA between all groups with normalized data\n",
    "add_anova_p(dset, ['0641', 'geh', 'sal', 'wt'], normed=True)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_* The above `RuntimeWarning` can be ignored in this case, it is caused by the presence of features that have all 0 intensities which gives a within-group variance of 0 and therefore causing devision by 0._ \n",
    "  \n",
    "  \n",
    "### 3.2) Pricipal Components Analysis (All Groups)\n",
    "PCA is an untargeted analysis that gives an indication of the overall variation between samples, as well as the individual features that contribute to this variation. We will compute a 3-component PCA in order to assess the variance between groups in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={\n",
       "\t\t\"ANOVA_0641-geh-sal-wt_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_loadings_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_projections_normed\"\n",
       "\t}\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.stats import add_pca3\n",
    "\n",
    "# compute PCA between all groups with normalized data\n",
    "add_pca3(dset, ['0641', 'geh', 'sal', 'wt'], normed=True)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have computed the 3-component PCA, and we can see two new stats entries in our dataset: \"PCA3_0641-geh-sal1-wt_projections_normed\" and \"PCA3_0641-geh-sal1-wt_loadings_normed\". Now we can take a look at the projections in a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipydomics.plotting import scatter_pca3_projections_bygroup\n",
    "\n",
    "# all groups normalized data\n",
    "scatter_pca3_projections_bygroup(dset, ['0641', 'geh', 'sal', 'wt'], './', normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the plot (`PCA3_0641-geh-sal1-wt_projections_normed.png`).\n",
    "\n",
    "<img src=\"PCA3_0641-geh-sal1-wt_projections_normed.png\" width=\"400\" align=\"left\">\n",
    "  \n",
    "  \n",
    "It looks like `geh` and `wt` separate along PC1 while `sal1` and `wt` separate along PC2, so these might be a couple of good pairwise comparisons to explore further. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) PLS-DA and Correlation on `wt` and `geh`\n",
    "Partial least-squares discriminant analysis (PLS-DA) is an analysis that is similar to PCA, except it finds significant variance between two specified groups (_i.e._ it is a supervised analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={\n",
       "\t\t\"ANOVA_0641-geh-sal-wt_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_loadings_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_projections_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_loadings_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_projections_normed\"\n",
       "\t}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.stats import add_plsda\n",
    "\n",
    "# compute PLS-DA between 'wt' and 'geh' using raw data\n",
    "add_plsda(dset, ['wt', 'geh'], normed=True)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have computed the PLS-DA, and we can see two new stats entries in our dataset: \"PLS-DA_geh-wt_projections_normed\" and \"PLS-DA_geh-wt_loadings_normed\". Now we can take a look at the projections in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipydomics.plotting import scatter_plsda_projections_bygroup\n",
    "\n",
    "# groups wt vs. geh, normalized data\n",
    "scatter_plsda_projections_bygroup(dset, ['wt', 'geh'], './', normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the plot (`PLS-DA_projections_geh-wt_normed.png`).\n",
    "\n",
    "<img src=\"PLS-DA_projections_geh-wt_normed.png\" width=\"400\" align=\"left\">\n",
    "\n",
    "As expected, `geh` and `wt` separate cleanly along component 1 corresponding to between group differences. The spread of both groups along component 2, related to intra-group variance, is similar between both groups indicating a similar amount of variance in both groups uncorrelated between them. A similar targeted analysis is the Pearson correlation coefficient between the two groups, which we need to calculate in order to produce an S-plot and tease out which lipid features are driving the separation between `geh` and `wt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={\n",
       "\t\t\"ANOVA_0641-geh-sal-wt_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_loadings_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_projections_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_loadings_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_projections_normed\"\n",
       "\t\t\"2-group-corr_wt-geh_normed\"\n",
       "\t}\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.stats import add_2group_corr\n",
    "from lipydomics.plotting import splot_plsda_pcorr_bygroup\n",
    "\n",
    "# compute correlation between 'wt' and 'geh' using normalized data\n",
    "add_2group_corr(dset, ['wt', 'geh'], normed=True)\n",
    "\n",
    "# groups wt vs. geh, normalized data\n",
    "splot_plsda_pcorr_bygroup(dset, ['wt', 'geh'], './', normed=True)\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the plot that was generated (`S-Plot_geh-wt_normed.png`).\n",
    "\n",
    "<img src=\"S-Plot_geh-wt_normed.png\" width=\"400\" align=\"left\">\n",
    "\n",
    "There appear to be several lipid features that drive separation between `geh` and `wt`, as indicated by the points in the lower left (red) and upper right (blue) corners of the plot. The last step is to export the data and manually inspect these significant features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Export Dataset to Spreadsheet\n",
    "We need to export our processed Dataset into a spreadsheet format so that we can more closely inspect the data and identify the lipid features that drive the separation that we identified between the `geh` and `wt` groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.export_xlsx('example.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Examine Specific Lipids\n",
    "Manual inspection of the data has revealed a handful of individual lipid species that differ significantly between `geh` and `wt`:\n",
    "\n",
    "| abundant in | m/z | retention time | CCS | putative id | id level |\n",
    "| :---: | :---: | :---: | :---: | :--- | :--- |\n",
    "| `geh` | 874.7869 | 0.43 | 320.3 | TG(52:3)_[M+NH4]+ | meas_mz_ccs |\n",
    "| `geh` | 878.8154 | 0.62 | 322.7 | TG(52:1)_[M+NH4]+ | meas_mz_ccs |\n",
    "| `geh` | 848.7709 | 0.40 | 313.3 | TG(50:2)_[M+NH4]+ | theo_mz_ccs |\n",
    "| `geh` | 605.5523 | 0.86 | 267.7 | DG(36:1)_[M+H-H2O]+ | theo_mz_ccs |\n",
    "| `geh` | 591.5378 | 0.93 | 263.9 | DG(35:1)_[M+H-H2O]+ | theo_mz_ccs |\n",
    "| `wt` | 496.3423 | 4.15 | 229.8 | LPC(16:0)_[M+H]+ | meas_mz_ccs |\n",
    "| `wt` | 524.3729 | 4.08 | 235.1 | LPC(18:0)_[M+H]+ | meas_mz_ccs |\n",
    "| `wt` | 810.6031 | 3.46 | 295.3 | PC(36:1)_[M+Na]+ | meas_mz_ccs |\n",
    "| `wt` | 782.5729 | 3.50 | 290.5 | PG(35:0)_[M+NH4]+ | theo_mz_ccs |\n",
    "\n",
    "### 5.1) Generate Plots for Significant Lipid Features\n",
    "Now that we have identified some potentially significant lipid feautures, we need to generate some bar plots for comparison. To avoid clogging up our working directory, we will save the feature plots in the `features` directory. The m/z, retention time, and CCS values are all listed in `features.csv`, and we will use this to generate the barplots all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lipydomics.plotting import batch_barplot_feature_bygroup\n",
    "\n",
    "# tight search tolerance\n",
    "tol = [0.01, 0.1, 1.0]\n",
    "batch_barplot_feature_bygroup(dset, ['wt', 'geh'], 'features/', 'features.csv', tolerance=tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at all of the plots that have been generated in the `features/` directory.\n",
    "\n",
    "#### __Abundant in `geh`__\n",
    "<img src=\"features/bar_874.7869-0.43-320.3_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_878.8154-0.62-322.7_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_848.7709-0.40-313.3_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_605.5523-0.86-267.7_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_591.5378-0.93-263.9_geh-wt_normed.png\" width=\"200\">\n",
    "\n",
    "\n",
    "#### __Abundant in `wt`__\n",
    "<img src=\"features/bar_496.3423-4.15-229.8_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_524.3729-4.08-235.1_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_810.6031-3.46-295.3_geh-wt_normed.png\" width=\"200\">\n",
    "<img src=\"features/bar_782.5729-3.50-290.5_geh-wt_normed.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Generate a Heatmap of TGs \n",
    "There seems to be an upregulation of TGs in `geh` relative to `wt`, so it might be nice to see if there are any large-scale trends among TGs as a lipid class between these groups. In order to make this comparison, we will need to compute another statistic: the Log2(fold-change) between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "\tcsv=\"example_raw.csv\",\n",
       "\tesi_mode=\"pos\",\n",
       "\tsamples=16,\n",
       "\tfeatures=3342,\n",
       "\tidentified=2134,\n",
       "\tnormalized=True,\n",
       "\trt_calibrated=False,\n",
       "\text_var=False,\n",
       "\tgroup_indices={\n",
       "\t\t\"0641\": [0, 1, 2, 3]\n",
       "\t\t\"geh\": [4, 5, 6, 7]\n",
       "\t\t\"sal\": [8, 9, 10, 11]\n",
       "\t\t\"wt\": [12, 13, 14, 15]\n",
       "\t},\n",
       "\tstats={\n",
       "\t\t\"ANOVA_0641-geh-sal-wt_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_loadings_normed\"\n",
       "\t\t\"PCA3_0641-geh-sal-wt_projections_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_loadings_normed\"\n",
       "\t\t\"PLS-DA_wt-geh_projections_normed\"\n",
       "\t\t\"2-group-corr_wt-geh_normed\"\n",
       "\t\t\"LOG2FC_wt-geh_normed\"\n",
       "\t}\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lipydomics.stats import add_log2fc\n",
    "from lipydomics.plotting import heatmap_lipid_class_log2fc\n",
    "\n",
    "# compute Log2(fold-change) with normalized data\n",
    "add_log2fc(dset, ['wt', 'geh'], normed=True)\n",
    "\n",
    "# Lipid Class: TG\n",
    "# Groups: wt, geh\n",
    "# Save in Dir: ./\n",
    "# Data: normalized\n",
    "found_lipids = heatmap_lipid_class_log2fc('TG', dset, ['wt', 'geh'], './', normed=True)\n",
    "\n",
    "# save the Dataset in a serialized binary format in case we want to load again later\n",
    "dset.save_bin('example.pickle')\n",
    "\n",
    "dset  # take a look at the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the plot that was generated (`TG_geh-wt_log2fc_normed.png`).\n",
    "\n",
    "<img src=\"TG_geh-wt_log2fc_normed.png\" width=\"600\" align=\"left\">\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
