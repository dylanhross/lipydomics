{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Make a new Dataset\n",
      "2. Load previous Dataset\n",
      "1\n",
      "Please enter the path of the csv file you want to work with: \n",
      "example_raw.csv\n",
      "Does this file have headers? y/n\n",
      "y\n",
      "Would you like to auto-make groups? (y/n)\n",
      "y\n",
      "Data loaded successfully\n",
      "Dataset(\n",
      "\tcsv=\"example_raw.csv\",\n",
      "\tesi_mode=\"None\",\n",
      "\tsamples=20,\n",
      "\tfeatures=773,\n",
      "\tidentified=False,\n",
      "\tnormalized=False,\n",
      "\tgroup_indices={\n",
      "\t\t\"A\": [0, 1, 2, 3]\n",
      "\t\t\"B\": [4, 5, 6, 7]\n",
      "\t\t\"C\": [8, 9, 10, 11]\n",
      "\t\t\"D\": [12, 13, 14, 15]\n",
      "\t\t\"E\": [16, 17, 18, 19]\n",
      "\t},\n",
      "\tstats={}\n",
      ")\n",
      "What would you like to do with the data? \n",
      "1. Manage groups\n",
      "2. Filter Data\n",
      "3. Manage Statistics\n",
      "4. Make Plots\n",
      "5. Identification\n",
      "6. Normalize\n",
      "7. Overview of Dataset\n",
      "8. Download current data as CSV\n",
      "9. Save current Dataset\n",
      "'exit' to quit the interface\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "from lipydomics.data import Dataset\n",
    "import lipydomics.stats as stats\n",
    "import lipydomics.plotting as plotting\n",
    "import lipydomics.identification as identification\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"1. Make a new Dataset\")\n",
    "    print(\"2. Load previous Dataset\")\n",
    "    option = input()\n",
    "    c = True\n",
    "\n",
    "    def filter_d(mzs, rts, ccss, data):\n",
    "        filtered = data[(data[0] < int(mzs[0]) + int(mzs[1])) & (data[0] > int(mzs[0]) - int(mzs[1])) &\n",
    "                        (data[1] < int(rts[0]) + int(rts[1])) & (data[1] > int(rts[0]) - int(rts[1])) &\n",
    "                        (data[2] < int(ccss[0]) + int(ccss[1])) & (data[2] > int(ccss[0]) - int(ccss[1]))]\n",
    "        return filtered\n",
    "\n",
    "    if option == \"1\":\n",
    "        print(\"Please enter the path of the csv file you want to work with: \")\n",
    "        file = input()\n",
    "        try:\n",
    "            print(\"Does this file have headers? y/n\")\n",
    "            ans = input()\n",
    "            if ans == \"y\":\n",
    "                print(\"Would you like to auto-make groups? (y/n)\")\n",
    "                ans = input()\n",
    "                if ans == \"y\":\n",
    "                    with open(file, newline='') as f:\n",
    "                        reader = csv.reader(f)\n",
    "                        header = next(reader)\n",
    "                    header = header[3:]\n",
    "                    group_map = {}\n",
    "                    for i in range(len(header)):\n",
    "                        if header[i] not in group_map:\n",
    "                            group_map[header[i]] = [i]\n",
    "                        else:\n",
    "                            group_map[header[i]] = group_map[header[i]] + [i]\n",
    "                    data = Dataset(file)\n",
    "                    data.assign_groups(group_map)\n",
    "                else:\n",
    "                    data = Dataset(file)\n",
    "            else:\n",
    "                data = Dataset(file)\n",
    "            print(\"Data loaded successfully\")\n",
    "        except IOError:\n",
    "            print(\">> Error. Make sure the path specified is correct and the file exists\")\n",
    "            c = False\n",
    "    elif option == \"2\":\n",
    "        print(\"Please provide the path of data file you want to load\")\n",
    "        path = input()\n",
    "        try:\n",
    "            data = Dataset.load_bin(path)\n",
    "            print(\"Data loaded successfully\")\n",
    "        except IOError:\n",
    "            print(\">> Error. Make sure the path specified is correct and the file exists\")\n",
    "            c = False\n",
    "    if c:\n",
    "        print(data)\n",
    "        label_df = pd.DataFrame(data.labels)\n",
    "        int_df = pd.DataFrame(data.intensities)\n",
    "        df = pd.concat([label_df, int_df], axis=1, ignore_index=True, sort=False)\n",
    "    while c:\n",
    "        print(\"What would you like to do with the data? \")\n",
    "        print(\"1. Manage groups\")\n",
    "        print(\"2. Filter Data\")\n",
    "        print(\"3. Manage Statistics\")\n",
    "        print(\"4. Make Plots\")\n",
    "        print(\"5. Identification\")\n",
    "        print(\"6. Normalize\")\n",
    "        print(\"7. Overview of Dataset\")\n",
    "        print(\"8. Download current data as CSV\")\n",
    "        print(\"9. Save current Dataset\")\n",
    "        print(\"'exit' to quit the interface\")\n",
    "        option = input()\n",
    "        if option == \"1\":\n",
    "            print(\" 1. Assign Groups\")\n",
    "            print(\" 2. View Assigned Groups\")\n",
    "            print(\" 3. Get Data By Group(s)\")\n",
    "            option = input()\n",
    "            if option == \"b\":\n",
    "                continue\n",
    "            if option == \"1\":\n",
    "                cont = True\n",
    "                while cont:\n",
    "                    print(\">> Please provide a name for a group and its indices in order of Name > Starting index > \"\n",
    "                          \"Ending index.\\nExample: 'A 1 3'\")\n",
    "                    group = input()\n",
    "                    if group == \"b\":\n",
    "                        break\n",
    "                    group = group.split()\n",
    "                    d = {group[0]: range(int(group[1]), int(group[2]) + 1)}\n",
    "                    try:\n",
    "                        data.assign_groups(d)\n",
    "                        print(\"     >> Group assigned successfully\")\n",
    "                        print(\"     >> Would you like to assign more groups? (y/n)\")\n",
    "                        a = input()\n",
    "                        if a == \"n\":\n",
    "                            cont = False\n",
    "                    except ValueError:\n",
    "                        print(\n",
    "                            \">> Error. Make sure the provided indices are correct and the format of the input is\"\n",
    "                            \" like the provided example\")\n",
    "\n",
    "            if option == \"2\":\n",
    "                print(\" \" + data.group_indices)\n",
    "\n",
    "            if option == \"3\":\n",
    "                print(\">> Which group would you like to view?\")\n",
    "                name = input()\n",
    "                print(data.get_data_bygroup(name))\n",
    "\n",
    "        elif option == \"2\":\n",
    "            print(\"1. Single query\")\n",
    "            print(\"2. Batch query\")\n",
    "            option = input()\n",
    "            if option == \"b\":\n",
    "                continue\n",
    "            label_dat = data.labels\n",
    "            label_df = pd.DataFrame(label_dat)\n",
    "            if option == \"1\":\n",
    "                print(\">> M/Z range? (Ex. '150 10'  <--- This would be 150 plus or minus 10)\")\n",
    "                mz = input()\n",
    "                print(\">> Retention Time range? (Ex. '1 1' <--- This would be 1 plus or minus 1)\")\n",
    "                rt = input()\n",
    "                print(\">> CCS range? (Ex. '150 10'  <--- This would be 150 plus or minus 10)\")\n",
    "                ccs = input()\n",
    "                print(\">> Which group would you like to choose? ('All' to select the whole data)\")\n",
    "                group = input()\n",
    "                if group == \"b\":\n",
    "                    continue\n",
    "                try:\n",
    "                    if group == \"All\":\n",
    "                        cur_data = pd.DataFrame(data.intensities)\n",
    "                    else:\n",
    "                        cur_data = data.get_data_bygroup(group)\n",
    "                    int_df = pd.DataFrame(cur_data)\n",
    "                    cur_df = pd.concat([label_df, int_df], axis=1, ignore_index=True, sort=False)\n",
    "                    mzs = mz.split()\n",
    "                    rts = rt.split()\n",
    "                    ccss = ccs.split()\n",
    "                    filtered = filter_d(mzs, rts, ccss, cur_df)\n",
    "                    print(filtered)\n",
    "                except ValueError:\n",
    "                    print(\" >> That group has not been assigned\")\n",
    "\n",
    "            elif option == \"2\":\n",
    "                print(\">> Which group would you like to choose? ('All' to select the whole data)\")\n",
    "                group = input()\n",
    "                if group == \"b\":\n",
    "                    continue\n",
    "                try:\n",
    "                    if group == \"All\":\n",
    "                        cur_data = pd.DataFrame(data.intensities)\n",
    "                    else:\n",
    "                        cur_data = data.get_data_bygroup(group)\n",
    "                        int_df = pd.DataFrame(cur_data)\n",
    "                        cur_df = pd.concat([label_df, int_df], axis=1, ignore_index=True, sort=False)\n",
    "                except ValueError:\n",
    "                    print(\">> That group has not been assigned\")\n",
    "                print(\">> Path of the file with batch-query information\")\n",
    "                path = input()\n",
    "                query = pd.read_csv(path)\n",
    "                for index, row in query.iterrows():\n",
    "                    if index == 0:\n",
    "                        filtered = filter_d([row[\"m/z\"], row[\"m/z_tol\"]], [row[\"rt\"], row[\"rt_tol\"]],\n",
    "                                            [row[\"ccs\"], row[\"ccs_tol\"]], cur_df)\n",
    "                    else:\n",
    "                        filtered = pd.concat([filtered,\n",
    "                                              filter_d([int(row[\"m/z\"]), int(row[\"m/z_tol\"])],\n",
    "                                                       [row[\"rt\"], row[\"rt_tol\"]], [row[\"ccs\"], row[\"ccs_tol\"]],\n",
    "                                                       cur_df)])\n",
    "            print(filtered)\n",
    "            print(\">> Data filter success. Would you like to download the result as csv? (y/n)\")\n",
    "            option = input()\n",
    "            if option == \"y\":\n",
    "                print(\">> Please specify the path you want to save the csv file\")\n",
    "                path = input()\n",
    "                export_csv = filtered.to_csv('results.csv',\n",
    "                                             index=None, header=False)\n",
    "\n",
    "        elif option == \"3\":\n",
    "            print(\"1. Compute Statistics\")\n",
    "            print(\"2. View Statistics\")\n",
    "            print(\"3. Download CSV file of computed Statistics\")\n",
    "            option = input()\n",
    "            if option == \"1\":\n",
    "                print(\">> What would you like to do?\")\n",
    "                print(\"1. Anova-P\")\n",
    "                print(\"2. PCA3\")\n",
    "                print(\"3. PLS-DA\")\n",
    "                print(\"4. Two Group Correlation\")\n",
    "                option = input()\n",
    "                if option == \"b\":\n",
    "                    continue\n",
    "                print(\">> Which groups would you like to perform chosen Statistic on?\")\n",
    "                group = input()\n",
    "                print(\">> Would you like to use normalized data? (y/n)\")\n",
    "                norm = input()\n",
    "                if norm == \"y\":\n",
    "                    norm = True\n",
    "                else:\n",
    "                    norm = False\n",
    "                if group == \"b\":\n",
    "                    continue\n",
    "                group = group.split()\n",
    "                if option == \"1\":\n",
    "                    try:\n",
    "                        stats.add_anova_p(data, group, norm)\n",
    "                        print(\">> Statistic added successfully\")\n",
    "                    except ValueError:\n",
    "                        print(\">> Something went wrong\")\n",
    "                if option == \"2\":\n",
    "                    try:\n",
    "                        stats.add_pca3(data, group, norm)\n",
    "                        print(\">> Statistic added successfully\")\n",
    "                    except ValueError:\n",
    "                        print(\">> Something went wrong\")\n",
    "                if option == \"3\":\n",
    "                    try:\n",
    "                        stats.add_plsda(data, group, norm)\n",
    "                        print(\">> Statistic added successfully\")\n",
    "                    except ValueError:\n",
    "                        print(\">> Something went wrong\")\n",
    "                if option == \"4\":\n",
    "                    try:\n",
    "                        stats.add_2group_corr(data, group, norm)\n",
    "                        print(\">> Statistic added successfully\")\n",
    "                    except ValueError:\n",
    "                        print(\">> Something went wrong\")\n",
    "            elif option == \"2\":\n",
    "                print(data.stats)\n",
    "            elif option == \"3\":\n",
    "                path = \"\"\n",
    "                df = pd.DataFrame.from_dict(data.stats)\n",
    "                export = df.to_csv(r'C:\\Users\\narsi\\Desktop\\results.csv')\n",
    "        elif option == \"4\":\n",
    "            print(\"1. Bar plot feature by group\")\n",
    "            print(\"2. Scatter PCA3 Projections by group\")\n",
    "            print(\"3. Scatter PLS-DA Projections by group\")\n",
    "            print(\"4. S-Plot PLSA-DA and Pearson correlation by group\")\n",
    "\n",
    "            option = input()\n",
    "            if option == \"b\":\n",
    "                continue\n",
    "            print(\">> Where would you like to save the plot?\")\n",
    "            path = \"\"\n",
    "            print(\">> Which group would you like to plot?\")\n",
    "            group = input()\n",
    "            if group == \"b\":\n",
    "                continue\n",
    "            group = group.split()\n",
    "            print(\">> Would you like to use normalized data? (y/n)\")\n",
    "            norm = input()\n",
    "            if norm == \"y\":\n",
    "                norm = True\n",
    "            else:\n",
    "                norm = False\n",
    "            if option == \"1\":\n",
    "                print(\">> Feature Range? (Type M/Z RT CCS in this order)\")\n",
    "                feature = input()\n",
    "                feature = list(map(float, feature.split()))\n",
    "                plotting.barplot_feature_bygroup(data, group, path, norm, feature)\n",
    "            if option == \"2\":\n",
    "                try:\n",
    "                    plotting.scatter_pca3_projections_bygroup(data, group, path, norm)\n",
    "                except KeyError:\n",
    "                    print(\"Statistic not yet computed\")\n",
    "            if option == \"3\":\n",
    "                try:\n",
    "                    plotting.scatter_plsda_projections_bygroup(data, group, path, norm)\n",
    "                except KeyError:\n",
    "                    print(\"Statistic not yet computed\")\n",
    "            if option == \"4\":\n",
    "                try:\n",
    "                    plotting.splot_plsda_pcorr_bygroup(data, group, path, norm)\n",
    "                except KeyError:\n",
    "                    print(\"Statistic not yet computed\")\n",
    "        elif option == \"5\":\n",
    "            print(\">> Please type the tolerance for m/z, rt, and CCS, respectively (Ex. '0.1 0.1 0.01')\")\n",
    "            feature = input()\n",
    "            if feature == \"b\":\n",
    "                continue\n",
    "            feature = list(map(float, feature.split()))\n",
    "            print(\">> Level? (theo_mz', 'meas_mz_rt_ccs', 'any')\")\n",
    "            level = input()\n",
    "            if level == \"b\":\n",
    "                continue\n",
    "            try:\n",
    "                identification.add_feature_ids(data, feature, level)\n",
    "                print(\"Identification added successfully\")\n",
    "            except ValueError:\n",
    "                print(\"Something went wrong!\")\n",
    "\n",
    "        elif option == \"6\":\n",
    "            print(\"1. Internal\")\n",
    "            print(\"2. External\")\n",
    "            option = input()\n",
    "            if option == \"1\":\n",
    "                print(\">> Please provide the feature m/z, rt and CCS respectively (Ex. 150, 1, 150)\")\n",
    "                feat = input()\n",
    "                feat = feat.split()\n",
    "                print(\">> Please type the tolerance for m/z, rt, and CCS, respectively (Ex. '0.1 0.1 0.01')\")\n",
    "                tol = input()\n",
    "                tol = tol.split()\n",
    "                mzs = [int(feat[0]), int(tol[0])]\n",
    "                rts = [int(feat[1]), int(tol[1])]\n",
    "                ccses = [int(feat[2]), int(tol[2])]\n",
    "                filtered = filter_d(mzs, rts, ccses, df)\n",
    "                max_inten = max(filtered.iloc[0][3:])\n",
    "                norm = []\n",
    "                for i in range(3, len(filtered.iloc[0])):\n",
    "                    norm.append(filtered.iloc[0][i] / max_inten)\n",
    "                try:\n",
    "                    data.normalize(np.asarray(norm))\n",
    "                    print(\"Successfully normalized\")\n",
    "                except ValueError:\n",
    "                    print(\"Something went wrong\")\n",
    "\n",
    "            elif option == \"2\":\n",
    "                print(\"    >> Please provide a text file with the normalization values\")\n",
    "                path = input()\n",
    "                norm = []\n",
    "                with open(path) as fp:\n",
    "                    line = float(fp.readline())\n",
    "                    norm.append(line)\n",
    "                    while line:\n",
    "                        try:\n",
    "                            line = float(fp.readline())\n",
    "                            norm.append(line)\n",
    "                        except ValueError:\n",
    "                            break\n",
    "                try:\n",
    "                    data.normalize(np.asarray(norm))\n",
    "                    print(\"Successfully normalized\")\n",
    "                except ValueError:\n",
    "                    print(\"Something went wrong\")\n",
    "\n",
    "        elif option == \"7\":\n",
    "            print(data)\n",
    "\n",
    "        elif option == \"8\":\n",
    "            print(\"Where would you like to save?\")\n",
    "            path = input()\n",
    "            if path == \"b\":\n",
    "                continue\n",
    "            writer = pd.ExcelWriter('results.xlsx', engine='xlsxwriter')\n",
    "            df.to_excel(writer, sheet_name='Data')\n",
    "            for key in data.stats:\n",
    "                stats_df = pd.DataFrame(data.stats[key])\n",
    "                if \"PCA3\" in key and \"loadings\" in key:\n",
    "                    stats_df = stats_df.transpose()\n",
    "                stats_df.to_excel(writer, sheet_name=key)\n",
    "            m = 1\n",
    "            feat_dict = {}\n",
    "            if data.feat_ids is not None:\n",
    "                for feat in data.feat_ids:\n",
    "                    if type(feat) is list:\n",
    "                        m = max(m, len(feat))\n",
    "                for i in range(0, m):\n",
    "                    s = []\n",
    "                    for feat in data.feat_ids:\n",
    "                        if type(feat) is list:\n",
    "                            try:\n",
    "                                s.append(feat[i])\n",
    "                            except:\n",
    "                                s.append(\"\")\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                s.append(feat)\n",
    "                            else:\n",
    "                                s.append(\"\")\n",
    "                    feat_dict[i] = s\n",
    "            if data.normed_intensities is not None:\n",
    "                norm_df = pd.DataFrame(data.normed_intensities)\n",
    "                norm_label_df = pd.concat([label_df, norm_df], axis=1, ignore_index=True, sort=False)\n",
    "                norm_label_df.to_excel(writer, sheet_name=\"Normalized Intensities\")\n",
    "            iden_df = pd.DataFrame(feat_dict)\n",
    "            level_df = pd.DataFrame(data.feat_id_levels)\n",
    "            pd.concat([level_df, iden_df], axis=1, ignore_index=False, sort=False)\n",
    "            identification_df = pd.concat([level_df, iden_df], axis=1, ignore_index=True, sort=False)\n",
    "            identification_df.to_excel(writer, sheet_name='Identification')\n",
    "            writer.save()\n",
    "        elif option == \"9\":\n",
    "            print(\"Where do you want to save your data set?\")\n",
    "            path = input()\n",
    "            if path == \"b\":\n",
    "                continue\n",
    "            data.save_bin(path)\n",
    "            print(\"File saved successfully\")\n",
    "        elif option == \"exit\":\n",
    "            c = False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Make a new Dataset\n",
      "2. Load previous Dataset\n",
      "1\n",
      "Please enter the path of the csv file you want to work with: \n",
      "example_raw.csv\n",
      "Does this file have headers? y/n\n",
      "y\n",
      "Would you like to auto-make groups? (y/n)\n",
      "n\n",
      "Data loaded successfully\n",
      "Dataset(\n",
      "\tcsv=\"example_raw.csv\",\n",
      "\tesi_mode=\"None\",\n",
      "\tsamples=20,\n",
      "\tfeatures=773,\n",
      "\tidentified=False,\n",
      "\tnormalized=False,\n",
      "\tgroup_indices=None,\n",
      "\tstats={}\n",
      ")\n",
      "What would you like to do with the data? \n",
      "1. Manage groups\n",
      "2. Filter Data\n",
      "3. Manage Statistics\n",
      "4. Make Plots\n",
      "5. Identification\n",
      "6. Normalize\n",
      "7. Overview of Dataset\n",
      "8. Download current data as CSV\n",
      "9. Save current Dataset\n",
      "'exit' to quit the interface\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
